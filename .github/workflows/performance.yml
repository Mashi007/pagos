name: ğŸ“Š Performance Testing

# Trigger del pipeline
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 3 * * 0' # Cada domingo a las 3 AM
  workflow_dispatch:

jobs:
  # ========================================
  # ğŸš€ PERFORMANCE TESTING BACKEND
  # ========================================
  backend-performance:
    name: ğŸš€ Performance Backend
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: perf_test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: ğŸ“¦ Instalar dependencias
        run: |
          cd backend
          pip install -r requirements.txt
          pip install locust pytest-benchmark
      
      - name: ğŸ”§ Configurar entorno de performance
        run: |
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/perf_test_db" >> $GITHUB_ENV
          echo "SECRET_KEY=perf-test-secret-key" >> $GITHUB_ENV
          echo "ENVIRONMENT=testing" >> $GITHUB_ENV
          echo "DEBUG=false" >> $GITHUB_ENV
      
      - name: ğŸ—„ï¸ Preparar base de datos
        run: |
          cd backend
          alembic upgrade head
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/perf_test_db
      
      - name: ğŸš€ Iniciar servidor en background
        run: |
          cd backend
          uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: ğŸ” Verificar que el servidor estÃ© funcionando
        run: |
          curl -f http://localhost:8000/api/v1/health/render || exit 1
      
      - name: ğŸ“Š Ejecutar pruebas de carga con Locust
        run: |
          cd backend
          cat > locustfile.py << 'EOF'
          from locust import HttpUser, task, between
          import random
          import string
          
          class ApiUser(HttpUser):
              wait_time = between(1, 3)
              
              def on_start(self):
                  # Login para obtener token
                  response = self.client.post("/api/v1/auth/login", data={
                      "username": "itmaster@rapicreditca.com",
                      "password": "R@pi_2025**"
                  })
                  if response.status_code == 200:
                      self.token = response.json()["access_token"]
                      self.headers = {"Authorization": f"Bearer {self.token}"}
                  else:
                      self.token = None
                      self.headers = {}
              
              @task(3)
              def health_check(self):
                  self.client.get("/api/v1/health/render")
              
              @task(2)
              def get_clientes(self):
                  if self.token:
                      self.client.get("/api/v1/clientes/", headers=self.headers)
              
              @task(1)
              def create_cliente(self):
                  if self.token:
                      cedula = ''.join(random.choices(string.digits, k=8))
                      data = {
                          "cedula": f"V{cedula}",
                          "nombres": "Test",
                          "apellidos": "Performance",
                          "telefono": "+58412123456",
                          "email": f"test{cedula}@example.com",
                          "direccion": "Test Address",
                          "fecha_nacimiento": "1990-01-01",
                          "ocupacion": "Tester",
                          "modelo_vehiculo": "Test Model",
                          "concesionario": "Test Dealer",
                          "analista": "Test Analyst",
                          "estado": "ACTIVO"
                      }
                      self.client.post("/api/v1/clientes/", json=data, headers=self.headers)
          EOF
          
          # Ejecutar Locust por 2 minutos
          locust -f locustfile.py --host=http://localhost:8000 --users=10 --spawn-rate=2 --run-time=2m --headless --html=performance-report.html
      
      - name: ğŸ“Š Ejecutar pruebas de benchmark
        run: |
          cd backend
          cat > test_performance.py << 'EOF'
          import pytest
          import time
          from fastapi.testclient import TestClient
          from app.main import app
          
          client = TestClient(app)
          
          def test_health_check_performance():
              start_time = time.time()
              response = client.get("/api/v1/health/render")
              end_time = time.time()
              
              assert response.status_code == 200
              assert (end_time - start_time) < 0.1  # Debe responder en menos de 100ms
          
          def test_clientes_list_performance():
              # Login
              login_response = client.post("/api/v1/auth/login", data={
                  "username": "itmaster@rapicreditca.com",
                  "password": "R@pi_2025**"
              })
              token = login_response.json()["access_token"]
              headers = {"Authorization": f"Bearer {token}"}
              
              start_time = time.time()
              response = client.get("/api/v1/clientes/", headers=headers)
              end_time = time.time()
              
              assert response.status_code == 200
              assert (end_time - start_time) < 0.5  # Debe responder en menos de 500ms
          EOF
          
          pytest test_performance.py -v --benchmark-only
      
      - name: ğŸ“Š Subir reportes de performance
        uses: actions/upload-artifact@v3
        with:
          name: backend-performance-reports
          path: |
            backend/performance-report.html
            backend/.benchmarks/

  # ========================================
  # ğŸš€ PERFORMANCE TESTING FRONTEND
  # ========================================
  frontend-performance:
    name: ğŸš€ Performance Frontend
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
      
      - name: ğŸ“¦ Configurar Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: ğŸ“¦ Instalar dependencias
        run: |
          cd frontend
          npm ci
      
      - name: ğŸ—ï¸ Build para producciÃ³n
        run: |
          cd frontend
          npm run build
      
      - name: ğŸ“Š AnÃ¡lisis de bundle size
        run: |
          cd frontend
          npm install -g bundle-analyzer
          npx webpack-bundle-analyzer dist/static/js/*.js --report --mode static --no-open
      
      - name: ğŸ” Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          configPath: './frontend/.lighthouserc.json'
          uploadArtifacts: true
          temporaryPublicStorage: false
      
      - name: ğŸ“Š Subir reportes de performance frontend
        uses: actions/upload-artifact@v3
        with:
          name: frontend-performance-reports
          path: |
            frontend/lighthouse-results/
            frontend/bundle-report.html

  # ========================================
  # ğŸ“Š REPORTE DE PERFORMANCE
  # ========================================
  performance-report:
    name: ğŸ“Š Performance Report
    runs-on: ubuntu-latest
    needs: [backend-performance, frontend-performance]
    if: always()
    
    steps:
      - name: ğŸ“¥ Descargar reportes
        uses: actions/download-artifact@v3
        with:
          path: performance-reports
      
      - name: ğŸ“Š Generar reporte consolidado
        run: |
          echo "# ğŸ“Š Performance Report" > performance-summary.md
          echo "Fecha: $(date)" >> performance-summary.md
          echo "" >> performance-summary.md
          
          echo "## Backend Performance" >> performance-summary.md
          echo "âœ… Pruebas de carga completadas" >> performance-summary.md
          echo "âœ… Benchmarks ejecutados" >> performance-summary.md
          
          echo "" >> performance-summary.md
          echo "## Frontend Performance" >> performance-summary.md
          echo "âœ… Lighthouse CI completado" >> performance-summary.md
          echo "âœ… Bundle analysis completado" >> performance-summary.md
          
          echo "" >> performance-summary.md
          echo "## MÃ©tricas Objetivo" >> performance-summary.md
          echo "- ğŸ¯ Response Time: < 200ms" >> performance-summary.md
          echo "- ğŸ¯ Bundle Size: < 1MB" >> performance-summary.md
          echo "- ğŸ¯ Lighthouse Score: > 90" >> performance-summary.md
          
          cat performance-summary.md
      
      - name: ğŸ“Š Subir reporte consolidado
        uses: actions/upload-artifact@v3
        with:
          name: performance-summary
          path: performance-summary.md
      
      - name: ğŸ“± Notificar si hay problemas de performance
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: |
            âš ï¸ *Problemas de Performance Detectados*
            ğŸ“Š Sistema de PrÃ©stamos y Cobranza
            ğŸ“Š Branch: ${{ github.ref_name }}
            ğŸ‘¤ Usuario: ${{ github.actor }}
            ğŸ”— Ver detalles: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
