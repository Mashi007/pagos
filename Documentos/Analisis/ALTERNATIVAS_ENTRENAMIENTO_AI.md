# üß† Alternativas para Entrenar el AI - An√°lisis del C√≥digo Actual

## üìã Resumen Ejecutivo

Este documento analiza el c√≥digo actual del sistema de AI y propone alternativas para mejorar el entrenamiento y capacidades del asistente inteligente.

---

## üîç An√°lisis del C√≥digo Actual

### 1. **Sistema de Chat AI (OpenAI API)**

**Ubicaci√≥n**: `backend/app/api/v1/endpoints/configuracion.py`

**Estado Actual**:
- ‚úÖ Usa OpenAI API (GPT-3.5/GPT-4)
- ‚úÖ Sistema de prompts personalizables
- ‚úÖ Integraci√≥n con base de datos para contexto
- ‚úÖ Validaci√≥n de preguntas relacionadas con BD
- ‚úÖ Sistema de documentos AI para contexto adicional

**Caracter√≠sticas**:
- Endpoint: `/ai/chat`
- Acceso restringido a administradores
- Incluye resumen de BD, esquema, y documentos de contexto
- Sistema de palabras clave para validar preguntas

### 2. **Servicio de Machine Learning**

**Ubicaci√≥n**: `backend/app/services/ml_service.py`

**Estado Actual**:
- ‚ö†Ô∏è M√©todo `train_risk_model()` es solo un placeholder
- ‚úÖ Estructura b√°sica para cargar/guardar modelos
- ‚úÖ M√©todo `predict_risk()` implementado pero requiere modelo entrenado
- ‚úÖ Usa pickle para serializaci√≥n
- ‚úÖ Scikit-learn disponible en dependencias

**Limitaciones**:
- No hay implementaci√≥n real de entrenamiento
- No hay recolecci√≥n de datos hist√≥ricos para entrenamiento
- No hay pipeline de feature engineering

### 3. **Sistema de Documentos AI**

**Ubicaci√≥n**: `backend/app/models/documento_ai.py`

**Estado Actual**:
- ‚úÖ Tabla `documentos_ai` para almacenar documentos
- ‚úÖ Extracci√≥n de texto de PDF, TXT, DOCX
- ‚úÖ Procesamiento autom√°tico de contenido
- ‚úÖ Integraci√≥n con Chat AI para contexto

**Caracter√≠sticas**:
- Soporta: PDF, TXT, DOCX
- Almacena contenido extra√≠do en BD
- Sistema de activaci√≥n/desactivaci√≥n
- L√≠mite de 3 documentos por consulta

### 4. **Configuraci√≥n de Prompts**

**Ubicaci√≥n**: `frontend/src/components/configuracion/AIConfig.tsx`

**Estado Actual**:
- ‚úÖ Editor de prompts personalizados
- ‚úÖ Template con placeholders din√°micos
- ‚úÖ Sistema de guardado en configuraci√≥n

---

## üöÄ Alternativas de Entrenamiento

### **Opci√≥n 1: Fine-tuning con OpenAI (Recomendada para Chat AI)**

#### Descripci√≥n
Entrenar un modelo personalizado de OpenAI usando datos hist√≥ricos de conversaciones y respuestas del sistema.

#### Ventajas
- ‚úÖ Mejora directa del comportamiento del Chat AI
- ‚úÖ Mantiene compatibilidad con la infraestructura actual
- ‚úÖ No requiere infraestructura adicional
- ‚úÖ OpenAI maneja el entrenamiento

#### Implementaci√≥n
1. **Recolecci√≥n de datos**:
   - Guardar conversaciones exitosas
   - Crear tabla `conversaciones_ai` con:
     - Pregunta del usuario
     - Respuesta del AI
     - Contexto usado (resumen BD, documentos)
     - Calificaci√≥n/feedback del usuario
     - Timestamp

2. **Preparaci√≥n de datos**:
   - Formato JSONL para OpenAI
   - Estructura: `{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}`

3. **Entrenamiento**:
   - Usar OpenAI Fine-tuning API
   - Modelos soportados: `gpt-4o` (recomendado), `gpt-4o-2024-08-06` (versi√≥n espec√≠fica)
   - Nota: `gpt-3.5-turbo` y `gpt-4o-mini` NO est√°n disponibles para fine-tuning
   - Costo: ~$0.008 por 1K tokens de entrenamiento (gpt-4o)

4. **Integraci√≥n**:
   - Actualizar endpoint para usar modelo fine-tuned
   - Mantener fallback al modelo base

#### C√≥digo de Ejemplo
```python
# backend/app/services/ai_training_service.py
import openai
from typing import List, Dict
import json

class AITrainingService:
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)

    def preparar_datos_entrenamiento(
        self,
        conversaciones: List[Dict]
    ) -> str:
        """Preparar datos en formato JSONL para fine-tuning"""
        datos = []
        for conv in conversaciones:
            datos.append({
                "messages": [
                    {"role": "system", "content": conv["system_prompt"]},
                    {"role": "user", "content": conv["pregunta"]},
                    {"role": "assistant", "content": conv["respuesta"]}
                ]
            })

        # Guardar como JSONL
        archivo_jsonl = "training_data.jsonl"
        with open(archivo_jsonl, "w") as f:
            for item in datos:
                f.write(json.dumps(item) + "\n")

        return archivo_jsonl

    def crear_archivo_entrenamiento(self, archivo_jsonl: str):
        """Subir archivo a OpenAI"""
        with open(archivo_jsonl, "rb") as f:
            file = self.client.files.create(
                file=f,
                purpose="fine-tune"
            )
        return file.id

    def iniciar_entrenamiento(
        self,
        file_id: str,
        modelo_base: str = "gpt-4o"  # gpt-4o-mini no est√° disponible para fine-tuning
    ):
        """Iniciar job de fine-tuning"""
        job = self.client.fine_tuning.jobs.create(
            training_file=file_id,
            model=modelo_base
        )
        return job.id

    def verificar_estado(self, job_id: str):
        """Verificar estado del entrenamiento"""
        job = self.client.fine_tuning.jobs.retrieve(job_id)
        return {
            "status": job.status,
            "model": job.fine_tuned_model if hasattr(job, 'fine_tuned_model') else None,
            "error": job.error if hasattr(job, 'error') else None
        }
```

#### Requisitos
- OpenAI API Key con acceso a fine-tuning
- M√≠nimo 10 conversaciones de ejemplo (recomendado: 50+)
- Presupuesto para entrenamiento (~$10-50 por modelo)

---

### **Opci√≥n 2: RAG (Retrieval-Augmented Generation) Mejorado**

#### Descripci√≥n
Mejorar el sistema actual de documentos AI con embeddings y b√∫squeda sem√°ntica para encontrar contexto m√°s relevante.

#### Ventajas
- ‚úÖ Mejora la precisi√≥n sin reentrenar modelos
- ‚úÖ Escalable con m√°s documentos
- ‚úÖ Reduce costos de tokens (menos contexto innecesario)
- ‚úÖ Respuestas m√°s relevantes

#### Implementaci√≥n
1. **Generar embeddings**:
   - Usar OpenAI Embeddings API o modelos locales (sentence-transformers)
   - Crear embeddings para cada documento y chunk de texto

2. **Almacenamiento**:
   - Opci√≥n A: Vector database (Pinecone, Weaviate, Qdrant)
   - Opci√≥n B: PostgreSQL con pgvector (extensi√≥n)
   - Opci√≥n C: Almacenar en tabla `documento_ai_embeddings`

3. **B√∫squeda sem√°ntica**:
   - Convertir pregunta del usuario a embedding
   - Buscar documentos m√°s similares (cosine similarity)
   - Incluir solo documentos relevantes en el prompt

4. **Chunking inteligente**:
   - Dividir documentos grandes en chunks de ~500 tokens
   - Mantener contexto entre chunks relacionados

#### C√≥digo de Ejemplo
```python
# backend/app/services/rag_service.py
from typing import List, Dict
import numpy as np
from sentence_transformers import SentenceTransformer
import openai

class RAGService:
    def __init__(self, use_openai: bool = True):
        self.use_openai = use_openai
        if not use_openai:
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        else:
            self.client = openai.OpenAI()

    def generar_embedding(self, texto: str) -> List[float]:
        """Generar embedding para un texto"""
        if self.use_openai:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=texto
            )
            return response.data[0].embedding
        else:
            return self.model.encode(texto).tolist()

    def buscar_documentos_relevantes(
        self,
        pregunta: str,
        documentos: List[Dict],
        top_k: int = 3
    ) -> List[Dict]:
        """Buscar documentos m√°s relevantes usando embeddings"""
        pregunta_embedding = self.generar_embedding(pregunta)

        # Calcular similitud con cada documento
        scores = []
        for doc in documentos:
            if doc.get("embedding"):
                doc_embedding = doc["embedding"]
                # Cosine similarity
                similarity = np.dot(pregunta_embedding, doc_embedding) / (
                    np.linalg.norm(pregunta_embedding) * np.linalg.norm(doc_embedding)
                )
                scores.append((similarity, doc))

        # Ordenar por similitud y retornar top_k
        scores.sort(reverse=True, key=lambda x: x[0])
        return [doc for _, doc in scores[:top_k]]
```

#### Requisitos
- Instalar: `sentence-transformers` o usar OpenAI Embeddings API
- Extensi√≥n pgvector si se usa PostgreSQL
- Procesar documentos existentes para generar embeddings

---

### **Opci√≥n 3: Entrenamiento de Modelo de Riesgo Crediticio (ML)**

#### Descripci√≥n
Implementar el m√©todo `train_risk_model()` para crear un modelo predictivo de riesgo crediticio.

#### Ventajas
- ‚úÖ Predicciones autom√°ticas de riesgo
- ‚úÖ Aprendizaje de patrones hist√≥ricos
- ‚úÖ Mejora con m√°s datos
- ‚úÖ Decisiones m√°s objetivas

#### Implementaci√≥n
1. **Recolecci√≥n de datos**:
   - Hist√≥rico de pr√©stamos aprobados/rechazados
   - Caracter√≠sticas: edad, ingreso, deuda, historial de pagos, etc.
   - Variable objetivo: morosidad, default, aprobaci√≥n

2. **Feature Engineering**:
   - Variables num√©ricas: edad, ingreso, ratio deuda/ingreso
   - Variables categ√≥ricas: tipo de pr√©stamo, concesionario
   - Variables temporales: d√≠as desde √∫ltimo pr√©stamo
   - Variables agregadas: historial de pagos, morosidad previa

3. **Modelo**:
   - Algoritmo: Random Forest, XGBoost, o Neural Network
   - Validaci√≥n: train/test split, cross-validation
   - M√©tricas: accuracy, precision, recall, F1, ROC-AUC

4. **Entrenamiento**:
   - Pipeline automatizado
   - Reentrenamiento peri√≥dico (mensual/trimestral)
   - Versionado de modelos

#### C√≥digo de Ejemplo
```python
# backend/app/services/ml_service.py (completar train_risk_model)
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score
import pandas as pd

def train_risk_model(self, training_data: list) -> bool:
    """
    Entrenar modelo de riesgo crediticio

    Args:
        training_data: Lista de diccionarios con datos hist√≥ricos

    Returns:
        bool: True si se entren√≥ exitosamente
    """
    try:
        # Convertir a DataFrame
        df = pd.DataFrame(training_data)

        # Definir caracter√≠sticas (features)
        feature_columns = [
            'edad', 'ingreso', 'deuda_total', 'ratio_deuda_ingreso',
            'historial_pagos', 'dias_ultimo_prestamo', 'numero_prestamos_previos'
        ]

        # Variable objetivo
        target_column = 'riesgo'  # 'bajo', 'medio', 'alto'

        # Preparar datos
        X = df[feature_columns]
        y = df[target_column].map({'bajo': 0, 'medio': 1, 'alto': 2})

        # Dividir en train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # Escalar caracter√≠sticas
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Entrenar modelo
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        model.fit(X_train_scaled, y_train)

        # Evaluar
        y_pred = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        logger.info(f"‚úÖ Modelo entrenado. Accuracy: {accuracy:.2%}")
        logger.info(f"\n{classification_report(y_test, y_pred)}")

        # Guardar modelo y scaler
        self.models["risk_model"] = model
        self.scalers["risk_scaler"] = scaler

        # Guardar en archivo
        self.save_models()

        return True

    except Exception as e:
        logger.error(f"Error entrenando modelo: {e}", exc_info=True)
        return False
```

#### Requisitos
- Datos hist√≥ricos suficientes (m√≠nimo 100-200 casos)
- Variables objetivo claramente definidas
- Pipeline de recolecci√≥n de datos

---

### **Opci√≥n 4: Sistema H√≠brido: Fine-tuning + RAG + ML**

#### Descripci√≥n
Combinar las tres opciones anteriores para un sistema completo y robusto.

#### Arquitectura
```
Usuario pregunta
    ‚Üì
RAG Service ‚Üí Buscar documentos relevantes
    ‚Üì
ML Service ‚Üí Predecir riesgo si aplica
    ‚Üì
Fine-tuned Chat AI ‚Üí Generar respuesta con contexto
    ‚Üì
Respuesta final
```

#### Ventajas
- ‚úÖ M√°xima precisi√≥n y relevancia
- ‚úÖ M√∫ltiples fuentes de informaci√≥n
- ‚úÖ Aprendizaje continuo
- ‚úÖ Escalable y mantenible

#### Implementaci√≥n por Fases

**Fase 1: RAG Mejorado (2-3 semanas)**
- Implementar embeddings
- Mejorar b√∫squeda sem√°ntica
- Procesar documentos existentes

**Fase 2: Fine-tuning (1-2 semanas)**
- Recolectar conversaciones
- Preparar datos de entrenamiento
- Entrenar modelo inicial

**Fase 3: ML de Riesgo (2-4 semanas)**
- Recolectar datos hist√≥ricos
- Feature engineering
- Entrenar modelo de riesgo
- Integrar con Chat AI

**Fase 4: Optimizaci√≥n (continuo)**
- Monitoreo de m√©tricas
- Reentrenamiento peri√≥dico
- A/B testing de modelos

---

## üìä Comparaci√≥n de Alternativas

| Criterio | Fine-tuning | RAG Mejorado | ML Riesgo | H√≠brido |
|----------|-------------|--------------|-----------|---------|
| **Costo** | Medio ($10-50) | Bajo ($0-20/mes) | Bajo (gratis) | Alto ($50-100+) |
| **Tiempo Implementaci√≥n** | 1-2 semanas | 2-3 semanas | 2-4 semanas | 6-8 semanas |
| **Complejidad** | Media | Media | Alta | Muy Alta |
| **Mejora Inmediata** | Alta | Alta | Media | Muy Alta |
| **Mantenimiento** | Bajo | Medio | Alto | Muy Alto |
| **Escalabilidad** | Alta | Muy Alta | Media | Muy Alta |
| **Requisitos Datos** | 50+ conversaciones | Documentos existentes | 100+ pr√©stamos | Todos |

---

## üéØ Recomendaci√≥n

### **Corto Plazo (1-2 meses)**
1. **Implementar RAG Mejorado** (Opci√≥n 2)
   - Mejor ROI inmediato
   - Mejora la precisi√≥n sin grandes cambios
   - Aprovecha documentos existentes

2. **Iniciar recolecci√≥n de datos para Fine-tuning**
   - Crear tabla `conversaciones_ai`
   - Guardar conversaciones exitosas
   - Sistema de feedback de usuarios

### **Mediano Plazo (3-6 meses)**
3. **Fine-tuning del Chat AI** (Opci√≥n 1)
   - Una vez tengas 50+ conversaciones de calidad
   - Entrenar modelo personalizado
   - A/B testing con modelo base

4. **ML de Riesgo B√°sico** (Opci√≥n 3)
   - Si hay suficientes datos hist√≥ricos
   - Modelo simple inicial (Random Forest)
   - Integrar con proceso de aprobaci√≥n

### **Largo Plazo (6+ meses)**
5. **Sistema H√≠brido Completo** (Opci√≥n 4)
   - Integrar todas las mejoras
   - Pipeline automatizado de reentrenamiento
   - Monitoreo y optimizaci√≥n continua

---

## üìù Pr√≥ximos Pasos

1. **Decidir enfoque**: Elegir entre las opciones seg√∫n recursos y objetivos
2. **Crear plan de implementaci√≥n**: Detallar tareas y timeline
3. **Preparar infraestructura**: Dependencias, almacenamiento, APIs
4. **Recolecci√≥n de datos**: Iniciar proceso de recopilaci√≥n
5. **Prototipo**: Implementar versi√≥n m√≠nima viable
6. **Testing**: Validar con datos reales
7. **Despliegue**: Lanzar a producci√≥n con monitoreo

---

## üîó Referencias

- [OpenAI Fine-tuning Guide](https://platform.openai.com/docs/guides/fine-tuning)
- [RAG Best Practices](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [PostgreSQL pgvector](https://github.com/pgvector/pgvector)

---

**Fecha de An√°lisis**: 2025-01-XX
**Versi√≥n**: 1.0
**Autor**: An√°lisis Autom√°tico del C√≥digo

