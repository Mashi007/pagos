"""Sistema Temporal de An√°lisis de TimingIdentifica problemas relacionados con tiempo y sincronizaci√≥n"""\nimport logging\nimport statistics\nimport threading\nimport time\nfrom collections \nimport defaultdict, deque\nfrom datetime \nimport datetime, timedelta\nfrom typing \nimport Any, Dict\nfrom fastapi \nimport APIRouter, Depends, HTTPException\nfrom sqlalchemy.orm \nimport Session\nfrom app.api.deps \nimport get_current_user, get_db\nfrom app.core.security \nimport decode_token\nfrom app.models.user \nimport Userlogger = logging.getLogger(__name__)router = APIRouter()# ============================================# SISTEMA TEMPORAL DE AN√ÅLISIS DE TIMING# ============================================\nclass TemporalAnalysisSystem:\n    """Sistema temporal para an√°lisis de timing y sincronizaci√≥n"""    \ndef __init__(self):\n        self.timing_events = deque(maxlen=10000)  # Eventos de timing        self.clock_sync_data = deque(            maxlen=1000        )  # Datos de sincronizaci√≥n de reloj        self.token_lifecycle_data = deque(            maxlen=5000        )  # Datos de ciclo de vida de tokens        self.timing_correlations = {}  # Correlaciones temporales        self.lock = threading.Lock()        # Iniciar monitoreo temporal en background        self._start_temporal_monitoring()    \ndef _start_temporal_monitoring(self):\n        """Iniciar monitoreo temporal en background"""        \ndef monitoring_loop():\n            while True:\n                try:\n                    self._collect_timing_data()                    self._analyze_timing_patterns()                    time.sleep(60)  # Monitorear cada minuto                except Exception as e:\n                    logger.error(f"Error en monitoreo temporal:\n {e}")                    time.sleep(120)        thread = threading.Thread(target=monitoring_loop, daemon=True)        thread.start()        logger.info("‚è∞ Sistema temporal de an√°lisis iniciado")    \ndef _collect_timing_data(self):\n        """Recopilar datos de timing del sistema"""        with self.lock:\n            current_time = datetime.now()            # Datos de sincronizaci√≥n de reloj            clock_data = {                "timestamp":\n current_time,                "system_time":\n time.time(),                "datetime_now":\n current_time.isoformat(),                "timezone_offset":\n (                    current_time.utcoffset().total_seconds()                    if current_time.utcoffset()                    else 0                ),            }            self.clock_sync_data.append(clock_data)            # Verificar desviaci√≥n de tiempo            if len(self.clock_sync_data) >= 2:\n                prev_data = self.clock_sync_data[-2]                time_diff = (                    current_time - prev_data["timestamp"]                ).total_seconds()                expected_diff = 60.0  # Esperamos 60 segundos                if (                    abs(time_diff - expected_diff) > 5                ):\n  # M√°s de 5 segundos de desviaci√≥n                    logger.warning(                        f"‚ö†Ô∏è Desviaci√≥n de tiempo"                        + f"detectada:\n {time_diff \                        - expected_diff:\n.2f} segundos"                    )    \ndef _analyze_timing_patterns(self):\n        """Analizar patrones temporales"""        with self.lock:\n            if len(self.timing_events) < 10:\n                return            # Analizar patrones de timing en eventos recientes            recent_events = list(self.timing_events)[                -100:\n            ]  # √öltimos 100 eventos            # Agrupar por tipo de evento            event_timings = defaultdict(list)            for event in recent_events:\n                event_timings[event["event_type"]].append(event["timing_data"])            # Calcular estad√≠sticas de timing por tipo            timing_stats = {}            for event_type, timings in event_timings.items():\n                if timings:\n                    timing_stats[event_type] = {                        "avg_duration_ms":\n statistics.mean(                            [t.get("duration_ms", 0) for t in timings]                        ),                        "min_duration_ms":\n min(                            [t.get("duration_ms", 0) for t in timings]                        ),                        "max_duration_ms":\n max(                            [t.get("duration_ms", 0) for t in timings]                        ),                        "std_deviation_ms":\n (                            statistics.stdev(                                [t.get("duration_ms", 0) for t in timings]                            )                            if len(timings) > 1                            else 0                        ),                    }            # Detectar anomal√≠as temporales            self._detect_temporal_anomalies(timing_stats)    \ndef _detect_temporal_anomalies(self, timing_stats:\n Dict[str, Any]):\n        """Detectar anomal√≠as temporales"""        anomalies = []        for event_type, stats in timing_stats.items():\n            avg_duration = stats["avg_duration_ms"]            std_deviation = stats["std_deviation_ms"]            # Detectar eventos que toman mucho tiempo            if avg_duration > 5000:\n  # M√°s de 5 segundos                anomalies.append(                    {                        "type":\n "slow_event",                        "event_type":\n event_type,                        "avg_duration_ms":\n avg_duration,                        "severity":\n (                            "high" if avg_duration > 10000 else "medium"                        ),                    }                )            # Detectar alta variabilidad en timing            if (                std_deviation > avg_duration * 0.5            ):\n  # Desviaci√≥n > 50% del promedio                anomalies.append(                    {                        "type":\n "high_variability",                        "event_type":\n event_type,                        "std_deviation_ms":\n std_deviation,                        "avg_duration_ms":\n avg_duration,                        "variability_ratio":\n std_deviation / avg_duration,                    }                )        if anomalies:\n            logger.warning(                f"üö® Anomal√≠as temporales detectadas:\n {len(anomalies)}"            )            for anomaly in anomalies:\n                logger.warning(                    f"   - {anomaly['type']}:\n {anomaly['event_type']}"                )    \ndef log_timing_event(        self,        event_type:\n str,        timing_data:\n Dict[str, Any],        context:\n Dict[str, Any] = None,    ):\n        """Registrar evento de timing"""        with self.lock:\n            event = {                "event_id":\n f"timing_{len(self.timing_events)}_{int(time.time \                ())}",                "event_type":\n event_type,                "timestamp":\n datetime.now(),                "timing_data":\n timing_data,                "context":\n context or {},            }            self.timing_events.append(event)            logger.debug(f"‚è∞ Evento temporal registrado:\n {event_type}")    \ndef analyze_token_timing(self, token:\n str) -> Dict[str, Any]:\n        """Analizar timing espec√≠fico de un token"""        try:\n            payload = decode_token(token)            # Informaci√≥n temporal del token            iat_timestamp = payload.get("iat", 0)            exp_timestamp = payload.get("exp", 0)            current_time = datetime.now()            # Calcular tiempos            issued_time = (                datetime.fromtimestamp(iat_timestamp)                if iat_timestamp                else None            )            expires_time = (                datetime.fromtimestamp(exp_timestamp)                if exp_timestamp                else None            )            # An√°lisis temporal            timing_analysis = {                "token_timing":\n {                    "issued_at":\n (                        issued_time.isoformat() if issued_time else None                    ),                    "expires_at":\n (                        expires_time.isoformat() if expires_time else None                    ),                    "current_time":\n current_time.isoformat(),                    "age_seconds":\n (                        (current_time - issued_time).total_seconds()                        if issued_time                        else None                    ),                    "time_to_expiry_seconds":\n (                        (expires_time - current_time).total_seconds()                        if expires_time                        else None                    ),                    "is_expired":\n (                        expires_time < current_time if expires_time else None                    ),                },                "timing_issues":\n [],                "recommendations":\n [],            }            # Detectar problemas temporales            if issued_time and issued_time > current_time:\n                timing_analysis["timing_issues"].append(                    {                        "issue":\n "token_from_future",                        "description":\n "Token emitido en el futuro",                        "severity":\n "critical",                    }                )            if expires_time and expires_time < current_time:\n                timing_analysis["timing_issues"].append(                    {                        "issue":\n "token_expired",                        "description":\n "Token ya expirado",                        "severity":\n "high",                    }                )            if (                expires_time                and (expires_time - current_time).total_seconds() < 300            ):\n                timing_analysis["timing_issues"].append(                    {                        "issue":\n "token_expiring_soon",                        "description":\n "Token expira en menos de 5 minutos",                        "severity":\n "medium",                    }                )            # Generar recomendaciones            if timing_analysis["timing_issues"]:\n                timing_analysis["recommendations"].append(                    "üîÑ Renovar token inmediatamente"                )            else:\n                timing_analysis["recommendations"].append(                    "‚úÖ Timing del token es correcto"                )            return timing_analysis        except Exception as e:\n            return {                "error":\n str(e),                "token_timing":\n None,                "timing_issues":\n [                    {                        "issue":\n "token_decode_error",                        "description":\n str(e),                        "severity":\n "critical",                    }                ],                "recommendations":\n ["üîß Verificar formato del token"],            }    \ndef analyze_clock_synchronization(self) -> Dict[str, Any]:\n        """Analizar sincronizaci√≥n de reloj"""        with self.lock:\n            if len(self.clock_sync_data) < 2:\n                return {"error":\n "Datos de sincronizaci√≥n insuficientes"}            recent_data = list(self.clock_sync_data)[                -10:\n            ]  # √öltimos 10 registros            # Calcular desviaciones de tiempo            time_diffs = []            for i in range(1, len(recent_data)):\n                prev_time = recent_data[i - 1]["timestamp"]                curr_time = recent_data[i]["timestamp"]                diff = (curr_time - prev_time).total_seconds()                time_diffs.append(diff)            # An√°lisis de sincronizaci√≥n            sync_analysis = {                "clock_sync_status":\n "unknown",                "time_differences":\n time_diffs,                "avg_time_diff":\n (                    statistics.mean(time_diffs) if time_diffs else 0                ),                "time_diff_std":\n (                    statistics.stdev(time_diffs) if len(time_diffs) > 1 else 0                ),                "max_deviation":\n (                    max(time_diffs) - min(time_diffs) if time_diffs else 0                ),                "sync_issues":\n [],                "recommendations":\n [],            }            # Determinar estado de sincronizaci√≥n            avg_diff = sync_analysis["avg_time_diff"]            if abs(avg_diff - 60.0) < 1.0:\n  # Diferencia menor a 1 segundo                sync_analysis["clock_sync_status"] = "excellent"            elif abs(avg_diff - 60.0) < 5.0:\n  # Diferencia menor a 5 segundos                sync_analysis["clock_sync_status"] = "good"            elif abs(avg_diff - 60.0) < 10.0:\n  # Diferencia menor a 10 segundos                sync_analysis["clock_sync_status"] = "degraded"            else:\n                sync_analysis["clock_sync_status"] = "poor"            # Detectar problemas de sincronizaci√≥n            if sync_analysis["time_diff_std"] > 5.0:\n                sync_analysis["sync_issues"].append(                    {                        "issue":\n "high_time_variability",                        "description":\n "Alta variabilidad en intervalos de    tiempo",                        "severity":\n "medium",                    }                )            if sync_analysis["max_deviation"] > 30.0:\n                sync_analysis["sync_issues"].append(                    {                        "issue":\n "large_time_deviation",                        "description":\n "Gran desviaci√≥n en intervalos de    tiempo",                        "severity":\n "high",                    }                )            # Generar recomendaciones            if sync_analysis["clock_sync_status"] == "poor":\n                sync_analysis["recommendations"].append(                    "üîß Sincronizar reloj del sistema"                )            elif sync_analysis["clock_sync_status"] == "degraded":\n                sync_analysis["recommendations"].append(                    "‚ö†Ô∏è Monitorear sincronizaci√≥n de reloj"                )            else:\n                sync_analysis["recommendations"].append(                    "‚úÖ Sincronizaci√≥n de reloj correcta"                )            return sync_analysis    \ndef analyze_temporal_correlations(self) -> Dict[str, Any]:\n        """Analizar correlaciones temporales"""        with self.lock:\n            if len(self.timing_events) < 20:\n                return {                    "error":\n "Datos de eventos insuficientes para an√°lisis    de correlaciones"                }            recent_events = list(self.timing_events)[                -200:\n            ]  # √öltimos 200 eventos            # Agrupar eventos por ventanas de tiempo            time_windows = defaultdict(list)            for event in recent_events:\n                # Crear ventana de 5 minutos                window_key = event["timestamp"].replace(                    minute=(event["timestamp"].minute // 5) * 5,                    second=0,                    microsecond=0,                )                time_windows[window_key].append(event)            # Analizar correlaciones            correlations = {}            window_keys = sorted(time_windows.keys())            for i in range(len(window_keys) - 1):\n                current_window = time_windows[window_keys[i]]                next_window = time_windows[window_keys[i + 1]]                # Contar tipos de eventos en cada ventana                current_types = defaultdict(int)                next_types = defaultdict(int)                for event in current_window:\n                    current_types[event["event_type"]] += 1                for event in next_window:\n                    next_types[event["event_type"]] += 1                # Buscar correlaciones                for event_type in current_types:\n                    if event_type in next_types:\n                        correlation_strength = min(                            current_types[event_type], next_types[event_type]                        ) / max(                            current_types[event_type], next_types[event_type]                        )                        if correlation_strength > 0.7:\n  # Correlaci√≥n fuerte                            correlations[f"{event_type}_correlation"] = {                                "strength":\n correlation_strength,                                "current_count":\n current_types[event_type],                                "next_count":\n next_types[event_type],                            }            return {                "temporal_correlations":\n correlations,                "analysis_period":\n {                    "start_time":\n (                        window_keys[0].isoformat() if window_keys else None                    ),                    "end_time":\n (                        window_keys[-1].isoformat() if window_keys else None                    ),                    "total_windows":\n len(window_keys),                },                "correlation_summary":\n {                    "strong_correlations":\n len(                        [                            c                            for c in correlations.values()                            if c["strength"] > 0.8                        ]                    ),                    "medium_correlations":\n len(                        [                            c                            for c in correlations.values()                            if 0.6 < c["strength"] <= 0.8                        ]                    ),                    "weak_correlations":\n len(                        [                            c                            for c in correlations.values()                            if c["strength"] <= 0.6                        ]                    ),                },            }    \ndef get_temporal_summary(self) -> Dict[str, Any]:\n        """Obtener resumen temporal general"""        with self.lock:\n            current_time = datetime.now()            cutoff_time = current_time - timedelta(                hours=24            )  # √öltimas 24 horas            # Filtrar eventos recientes            recent_events = [                event                for event in self.timing_events                if event["timestamp"] > cutoff_time            ]            # Estad√≠sticas temporales            if recent_events:\n                durations = [                    event["timing_data"].get("duration_ms", 0)                    for event in recent_events                ]                avg_duration = statistics.mean(durations) if durations else 0                max_duration = max(durations) if durations else 0                min_duration = min(durations) if durations else 0            else:\n                avg_duration = max_duration = min_duration = 0            # An√°lisis de sincronizaci√≥n de reloj            clock_sync_analysis = self.analyze_clock_synchronization()            return {                "timestamp":\n current_time.isoformat(),                "summary":\n {                    "total_events_24h":\n len(recent_events),                    "avg_event_duration_ms":\n avg_duration,                    "max_event_duration_ms":\n max_duration,                    "min_event_duration_ms":\n min_duration,                    "clock_sync_status":\n clock_sync_analysis.get(                        "clock_sync_status", "unknown"                    ),                    "sync_issues_count":\n len(                        clock_sync_analysis.get("sync_issues", [])                    ),                },                "clock_sync_analysis":\n clock_sync_analysis,                "recent_timing_events":\n (                    recent_events[-10:\n] if recent_events else []                ),            }# Instancia global del sistema temporaltemporal_system = TemporalAnalysisSystem()# ============================================# ENDPOINTS TEMPORALES# ============================================@router.post("/log-timing-event")async \ndef log_timing_event_endpoint(    event_data:\n Dict[str, Any],    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    ‚è∞ Registrar evento de timing    """    try:\n        event_type = event_data.get("event_type")        timing_data = event_data.get("timing_data", {})        context = event_data.get("context", {})        if not event_type:\n            raise HTTPException(status_code=400, detail="event_type requerido")        temporal_system.log_timing_event(event_type, timing_data, context)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "logged",            "message":\n "Evento temporal registrado",        }    except HTTPException:\n        raise    except Exception as e:\n        logger.error(f"Error registrando evento temporal:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.post("/analyze-token-timing")async \ndef analyze_token_timing_endpoint(    token_data:\n Dict[str, str],    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    üîç Analizar timing espec√≠fico de un token    """    try:\n        token = token_data.get("token")        if not token:\n            raise HTTPException(status_code=400, detail="Token requerido")        analysis = temporal_system.analyze_token_timing(token)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "analysis":\n analysis,        }    except HTTPException:\n        raise    except Exception as e:\n        logger.error(f"Error analizando timing de token:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/clock-synchronization")async \ndef get_clock_synchronization_analysis(    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    üïê An√°lisis de sincronizaci√≥n de reloj    """    try:\n        analysis = temporal_system.analyze_clock_synchronization()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "analysis":\n analysis,        }    except Exception as e:\n        logger.error(f"Error analizando sincronizaci√≥n de reloj:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/temporal-correlations")async \ndef get_temporal_correlations_analysis(    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    üîó An√°lisis de correlaciones temporales    """    try:\n        analysis = temporal_system.analyze_temporal_correlations()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "analysis":\n analysis,        }    except Exception as e:\n        logger.error(f"Error analizando correlaciones temporales:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/temporal-summary")async \ndef get_temporal_summary_endpoint(    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    üìä Resumen temporal general    """    try:\n        summary = temporal_system.get_temporal_summary()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "summary":\n summary,        }    except Exception as e:\n        logger.error(f"Error obteniendo resumen temporal:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }
