"""Sistema de Análisis de Fallos IntermitentesIdentifica patrones específicos que causan fallos 401 intermitentes"""\nimport logging\nimport statistics\nimport threading\nfrom collections \nimport defaultdict, deque\nfrom datetime \nimport datetime, timedelta\nfrom typing \nimport Any, Dict, List\nfrom fastapi \nimport APIRouter, Depends\nfrom sqlalchemy.orm \nimport Session\nfrom app.api.deps \nimport get_current_user, get_db\nfrom app.models.user \nimport Userlogger = logging.getLogger(__name__)router = APIRouter()# ============================================# SISTEMA DE ANÁLISIS DE FALLOS INTERMITENTES# ============================================\nclass IntermittentFailureAnalyzer:\n    """Analizador de fallos intermitentes específicos"""    \ndef __init__(self):\n        self.successful_requests = deque(maxlen=1000)  # Requests exitosos        self.failed_requests = deque(maxlen=1000)  # Requests fallidos        self.intermittent_patterns = {}  # Patrones intermitentes        self.lock = threading.Lock()    \ndef log_successful_request(self, request_data:\n Dict[str, Any]):\n        """Registrar request exitoso"""        with self.lock:\n            request = {                "timestamp":\n datetime.now(),                "endpoint":\n request_data.get("endpoint"),                "method":\n request_data.get("method"),                "user_id":\n request_data.get("user_id"),                "token_length":\n request_data.get("token_length"),                "response_time_ms":\n request_data.get("response_time_ms"),                "client_ip":\n request_data.get("client_ip"),                "user_agent":\n request_data.get("user_agent"),                "success":\n True,            }            self.successful_requests.append(request)            logger.debug(                f"✅ Request exitoso registrado:\n {request['endpoint']}"            )    \ndef log_failed_request(self, request_data:\n Dict[str, Any]):\n        """Registrar request fallido"""        with self.lock:\n            request = {                "timestamp":\n datetime.now(),                "endpoint":\n request_data.get("endpoint"),                "method":\n request_data.get("method"),                "user_id":\n request_data.get("user_id"),                "token_length":\n request_data.get("token_length"),                "error_type":\n request_data.get("error_type"),                "error_message":\n request_data.get("error_message"),                "client_ip":\n request_data.get("client_ip"),                "user_agent":\n request_data.get("user_agent"),                "success":\n False,            }            self.failed_requests.append(request)            logger.warning(                f"❌ Request fallido"                + f"registrado:\n {request['endpoint']} \                - {request['error_type']}"            )    \ndef analyze_intermittent_patterns(self) -> Dict[str, Any]:\n        """Analizar patrones de fallos intermitentes"""        with self.lock:\n            if not self.successful_requests or not self.failed_requests:\n                return {"error":\n "Datos insuficientes para análisis"}            analysis = {                "timestamp":\n datetime.now().isoformat(),                "summary":\n self._analyze_request_summary(),                "intermittent_patterns":\n    self._identify_intermittent_patterns(),                "specific_failure_triggers":\n self._identify_failure_triggers(),                "timing_analysis":\n self._analyze_timing_patterns(),                "recommendations":\n [],            }            return analysis    \ndef _analyze_request_summary(self) -> Dict[str, Any]:\n        """Analizar resumen de requests"""        successful_count = len(self.successful_requests)        failed_count = len(self.failed_requests)        total_count = successful_count + failed_count        # Análisis por endpoint        successful_endpoints = defaultdict(int)        failed_endpoints = defaultdict(int)        for req in self.successful_requests:\n            successful_endpoints[req["endpoint"]] += 1        for req in self.failed_requests:\n            failed_endpoints[req["endpoint"]] += 1        return {            "total_requests":\n total_count,            "successful_requests":\n successful_count,            "failed_requests":\n failed_count,            "success_rate":\n (                (successful_count / total_count * 100)                if total_count > 0                else 0            ),            "successful_endpoints":\n dict(successful_endpoints),            "failed_endpoints":\n dict(failed_endpoints),        }    \ndef _analizar_patrones_endpoint(self) -> Dict[str, Any]:\n        """Analizar patrones intermitentes por endpoint"""        endpoint_patterns = {}        # Obtener todos los endpoints únicos        all_endpoints = set()        for req in self.successful_requests:\n            all_endpoints.add(req["endpoint"])        for req in self.failed_requests:\n            all_endpoints.add(req["endpoint"])        for endpoint in all_endpoints:\n            successful_for_endpoint = [                req                for req in self.successful_requests                if req["endpoint"] == endpoint            ]            failed_for_endpoint = [                req                for req in self.failed_requests                if req["endpoint"] == endpoint            ]            if successful_for_endpoint and failed_for_endpoint:\n                endpoint_patterns[endpoint] = {                    "successful_count":\n len(successful_for_endpoint),                    "failed_count":\n len(failed_for_endpoint),                    "intermittency_score":\n (                        len(failed_for_endpoint)                        / (                            len(successful_for_endpoint)                            + len(failed_for_endpoint)                        )                    ),                }        return endpoint_patterns    \ndef _analizar_patrones_usuario(self) -> Dict[str, Any]:\n        """Analizar patrones intermitentes por usuario"""        user_patterns = {}        # Obtener todos los usuarios únicos        all_users = set()        for req in self.successful_requests:\n            if req.get("user_id"):\n                all_users.add(req["user_id"])        for req in self.failed_requests:\n            if req.get("user_id"):\n                all_users.add(req["user_id"])        for user_id in all_users:\n            successful_for_user = [                req                for req in self.successful_requests                if req.get("user_id") == user_id            ]            failed_for_user = [                req                for req in self.failed_requests                if req.get("user_id") == user_id            ]            if successful_for_user and failed_for_user:\n                user_patterns[str(user_id)] = {                    "successful_count":\n len(successful_for_user),                    "failed_count":\n len(failed_for_user),                    "failure_rate":\n (                        len(failed_for_user)                        / (len(successful_for_user) + len(failed_for_user))                        * 100                    ),                }        return user_patterns    \ndef _identify_intermittent_patterns(self) -> Dict[str, Any]:\n        """Identificar patrones intermitentes específicos     (VERSIÓN REFACTORIZADA)"""        patterns = {            "endpoint_intermittency":\n self._analizar_patrones_endpoint(),            "user_specific_patterns":\n self._analizar_patrones_usuario(),            "timing_patterns":\n {},            "token_patterns":\n {},        }        return patterns    \ndef _identify_failure_triggers(self) -> Dict[str, Any]:\n        """Identificar triggers específicos de fallo"""        triggers = {            "token_length_patterns":\n {},            "timing_triggers":\n {},            "client_patterns":\n {},            "error_type_patterns":\n {},        }        # Patrones de longitud de token        successful_token_lengths = [            req.get("token_length", 0)            for req in self.successful_requests            if req.get("token_length")        ]        failed_token_lengths = [            req.get("token_length", 0)            for req in self.failed_requests            if req.get("token_length")        ]        if successful_token_lengths and failed_token_lengths:\n            triggers["token_length_patterns"] = {                "successful_avg_length":\n statistics.mean(                    successful_token_lengths                ),                "failed_avg_length":\n statistics.mean(failed_token_lengths),                "length_difference":\n (                    statistics.mean(successful_token_lengths)                    - statistics.mean(failed_token_lengths)                ),            }        # Patrones de timing        successful_times = [            req.get("response_time_ms", 0)            for req in self.successful_requests            if req.get("response_time_ms")        ]        failed_times = [            req.get("response_time_ms", 0)            for req in self.failed_requests            if req.get("response_time_ms")        ]        if successful_times and failed_times:\n            triggers["timing_triggers"] = {                "successful_avg_time":\n statistics.mean(successful_times),                "failed_avg_time":\n statistics.mean(failed_times),                "time_difference":\n (                    statistics.mean(successful_times)                    - statistics.mean(failed_times)                ),            }        # Patrones de cliente        successful_ips = [            req.get("client_ip")            for req in self.successful_requests            if req.get("client_ip")        ]        failed_ips = [            req.get("client_ip")            for req in self.failed_requests            if req.get("client_ip")        ]        successful_ip_counts = defaultdict(int)        failed_ip_counts = defaultdict(int)        for ip in successful_ips:\n            successful_ip_counts[ip] += 1        for ip in failed_ips:\n            failed_ip_counts[ip] += 1        triggers["client_patterns"] = {            "successful_ip_distribution":\n dict(successful_ip_counts),            "failed_ip_distribution":\n dict(failed_ip_counts),        }        # Patrones de tipo de error        error_types = defaultdict(int)        for req in self.failed_requests:\n            error_type = req.get("error_type", "unknown")            error_types[error_type] += 1        triggers["error_type_patterns"] = dict(error_types)        return triggers    \ndef _analyze_timing_patterns(self) -> Dict[str, Any]:\n        """Analizar patrones de timing específicos"""        # Combinar todos los requests y ordenar por tiempo        all_requests = []        for req in self.successful_requests:\n            all_requests.append({**req, "success":\n True})        for req in self.failed_requests:\n            all_requests.append({**req, "success":\n False})        all_requests.sort(key=lambda x:\n x["timestamp"])        # Buscar secuencias de fallos        failure_sequences = []        current_sequence = []        for req in all_requests:\n            if not req["success"]:\n                current_sequence.append(req)            else:\n                if current_sequence:\n                    failure_sequences.append(current_sequence.copy())                    current_sequence = []        if current_sequence:\n            failure_sequences.append(current_sequence)        # Analizar patrones temporales        timing_analysis = {            "total_requests_analyzed":\n len(all_requests),            "failure_sequences_count":\n len(failure_sequences),            "longest_failure_sequence":\n (                max([len(seq) for seq in failure_sequences])                if failure_sequences                else 0            ),            "average_sequence_length":\n (                statistics.mean([len(seq) for seq in failure_sequences])                if failure_sequences                else 0            ),        }        # Buscar patrones de recuperación        recovery_patterns = []        for i in range(len(all_requests) - 1):\n            if (                not all_requests[i]["success"]                and all_requests[i + 1]["success"]            ):\n                recovery_time = (                    all_requests[i + 1]["timestamp"]                    - all_requests[i]["timestamp"]                ).total_seconds()                recovery_patterns.append(recovery_time)        if recovery_patterns:\n            timing_analysis["recovery_patterns"] = {                "avg_recovery_time_seconds":\n statistics.mean(                    recovery_patterns                ),                "min_recovery_time_seconds":\n min(recovery_patterns),                "max_recovery_time_seconds":\n max(recovery_patterns),            }        return timing_analysis    \ndef get_intermittent_summary(self) -> Dict[str, Any]:\n        """Obtener resumen de análisis intermitente"""        with self.lock:\n            current_time = datetime.now()            cutoff_time = current_time - timedelta(hours=1)  # Última hora            # Filtrar requests recientes            recent_successful = [                req                for req in self.successful_requests                if req["timestamp"] > cutoff_time            ]            recent_failed = [                req                for req in self.failed_requests                if req["timestamp"] > cutoff_time            ]            return {                "timestamp":\n current_time.isoformat(),                "summary":\n {                    "recent_successful_requests":\n len(recent_successful),                    "recent_failed_requests":\n len(recent_failed),                    "total_successful_requests":\n len(self.successful_requests),                    "total_failed_requests":\n len(self.failed_requests),                    "intermittency_detected":\n len(recent_successful) > 0                    and len(recent_failed) > 0,                },                "recent_patterns":\n self._analyze_recent_patterns(                    recent_successful, recent_failed                ),            }    \ndef _analyze_recent_patterns(        self, recent_successful:\n List[Dict], recent_failed:\n List[Dict]    ) -> Dict[str, Any]:\n        """Analizar patrones recientes"""        if not recent_successful or not recent_failed:\n            return {"status":\n "insufficient_data"}        # Identificar endpoints con comportamiento intermitente        intermittent_endpoints = []        successful_endpoints = set(            req["endpoint"] for req in recent_successful        )        failed_endpoints = set(req["endpoint"] for req in recent_failed)        common_endpoints = successful_endpoints & failed_endpoints        for endpoint in common_endpoints:\n            successful_count = len(                [                    req                    for req in recent_successful                    if req["endpoint"] == endpoint                ]            )            failed_count = len(                [req for req in recent_failed if req["endpoint"] == endpoint]            )            intermittent_endpoints.append(                {                    "endpoint":\n endpoint,                    "successful_count":\n successful_count,                    "failed_count":\n failed_count,                    "intermittency_ratio":\n failed_count                    / (successful_count + failed_count),                }            )        return {            "intermittent_endpoints":\n intermittent_endpoints,            "common_endpoints_count":\n len(common_endpoints),            "total_endpoints_with_failures":\n len(failed_endpoints),        }# Instancia global del analizador intermitenteintermittent_analyzer = IntermittentFailureAnalyzer()# ============================================# ENDPOINTS DE ANÁLISIS INTERMITENTE# ============================================router.post("/log-successful-request")async \ndef log_successful_request_endpoint(    request_data:\n Dict[str, Any],    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    ✅ Registrar request exitoso para análisis intermitente    """    try:\n        intermittent_analyzer.log_successful_request(request_data)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "logged",            "message":\n "Request exitoso registrado",        }    except Exception as e:\n        logger.error(f"Error registrando request exitoso:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }router.post("/log-failed-request")async \ndef log_failed_request_endpoint(    request_data:\n Dict[str, Any],    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    ❌ Registrar request fallido para análisis intermitente    """    try:\n        intermittent_analyzer.log_failed_request(request_data)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "logged",            "message":\n "Request fallido registrado",        }    except Exception as e:\n        logger.error(f"Error registrando request fallido:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }router.get("/intermittent-patterns")async \ndef get_intermittent_patterns(    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    🔄 Análisis de patrones intermitentes    """    try:\n        analysis = intermittent_analyzer.analyze_intermittent_patterns()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "analysis":\n analysis,        }    except Exception as e:\n        logger.error(f"Error analizando patrones intermitentes:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }router.get("/intermittent-summary")async \ndef get_intermittent_summary_endpoint(    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    📊 Resumen de análisis intermitente    """    try:\n        summary = intermittent_analyzer.get_intermittent_summary()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "summary":\n summary,        }    except Exception as e:\n        logger.error(f"Error obteniendo resumen intermitente:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }
