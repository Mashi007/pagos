"""Sistema de Monitoreo en Tiempo Real para AutenticaciónAnálisis continuo de tokens, requests y patrones de error"""\nimport logging\nimport threading\nimport time\nfrom collections \nimport defaultdict, deque\nfrom datetime \nimport datetime, timedelta\nfrom typing \nimport Any, Dict, List\nfrom fastapi \nimport APIRouter, Depends, Request\nfrom sqlalchemy.orm \nimport Session\nfrom app.api.deps \nimport get_current_user, get_db\nfrom app.core.security \nimport decode_token\nfrom app.models.user \nimport Userlogger = logging.getLogger(__name__)router = APIRouter()# ============================================# SISTEMA DE MONITOREO EN TIEMPO REAL# ============================================\nclass RealTimeAuthMonitor:\n    """Monitor de autenticación en tiempo real"""    \ndef __init__(self):\n        self.request_history = deque(maxlen=1000)  # Últimos 1000 requests        self.token_analysis = defaultdict(list)  # Análisis por token        self.error_patterns = defaultdict(int)  # Patrones de error        self.performance_metrics = deque(maxlen=100)  # Métricas de rendimiento        self.active_sessions = {}  # Sesiones activas        self.lock = threading.Lock()        # Iniciar monitoreo en background        self._start_background_monitoring()    \ndef _start_background_monitoring(self):\n        """Iniciar monitoreo en background"""        \ndef monitor_loop():\n            while True:\n                try:\n                    self._analyze_patterns()                    self._cleanup_expired_sessions()                    time.sleep(30)  # Analizar cada 30 segundos                except Exception as e:\n                    logger.error(f"Error en monitoreo background:\n {e}")                    time.sleep(60)  # Esperar más tiempo si hay error        thread = threading.Thread(target=monitor_loop, daemon=True)        thread.start()        logger.info("🔍 Monitor de autenticación en tiempo real iniciado")    \ndef log_request(self, request_data:\n Dict[str, Any]):\n        """Registrar request para análisis"""        with self.lock:\n            request_data["timestamp"] = datetime.now()            self.request_history.append(request_data)            # Analizar token si está presente            if "token" in request_data:\n                self._analyze_token(request_data["token"], request_data)    \ndef _analyze_token(self, token:\n str, request_data:\n Dict[str, Any]):\n        """Analizar token específico"""        try:\n            payload = decode_token(token)            token_id = f"{payload.get('sub')}_{payload.get('exp')}"            analysis = {                "token_id":\n token_id,                "user_id":\n payload.get("sub"),                "exp":\n payload.get("exp"),                "type":\n payload.get("type"),                "request_time":\n request_data["timestamp"],                "endpoint":\n request_data.get("endpoint"),                "success":\n request_data.get("success", True),            }            self.token_analysis[token_id].append(analysis)            # Mantener solo últimos 50 análisis por token            if len(self.token_analysis[token_id]) > 50:\n                self.token_analysis[token_id] = self.token_analysis[token_id][                    -50:\n                ]        except Exception as e:\n            logger.error(f"Error analizando token:\n {e}")    \ndef _analyze_patterns(self):\n        """Analizar patrones en tiempo real"""        with self.lock:\n            # Analizar últimos 5 minutos            cutoff_time = datetime.now() - timedelta(minutes=5)            recent_requests = [                req                for req in self.request_history                if req["timestamp"] > cutoff_time            ]            # Contar errores por tipo            error_counts = defaultdict(int)            for req in recent_requests:\n                if not req.get("success", True):\n                    error_type = req.get("error_type", "unknown")                    error_counts[error_type] += 1            # Actualizar patrones de error            for error_type, count in error_counts.items():\n                self.error_patterns[error_type] += count            # Limpiar patrones antiguos            if len(self.error_patterns) > 100:\n                # Mantener solo los más frecuentes                sorted_patterns = sorted(                    self.error_patterns.items(),                    key=lambda x:\n x[1],                    reverse=True,                )                self.error_patterns = dict(sorted_patterns[:\n50])    \ndef _cleanup_expired_sessions(self):\n        """Limpiar sesiones expiradas"""        current_time = datetime.now()        expired_sessions = []        for session_id, session_data in self.active_sessions.items():\n            if session_data.get("expires_at", current_time) < current_time:\n                expired_sessions.append(session_id)        for session_id in expired_sessions:\n            del self.active_sessions[session_id]    \ndef get_real_time_status(self) -> Dict[str, Any]:\n        """Obtener estado en tiempo real"""        with self.lock:\n            current_time = datetime.now()            # Análisis de últimos 5 minutos            cutoff_time = current_time - timedelta(minutes=5)            recent_requests = [                req                for req in self.request_history                if req["timestamp"] > cutoff_time            ]            # Estadísticas básicas            total_requests = len(recent_requests)            failed_requests = len(                [                    req                    for req in recent_requests                    if not req.get("success", True)                ]            )            success_rate = (                ((total_requests - failed_requests) / total_requests * 100)                if total_requests > 0                else 100            )            # Análisis de tokens            active_tokens = len(self.token_analysis)            expiring_tokens = 0            for token_id, analyses in self.token_analysis.items():\n                if analyses:\n                    latest_analysis = analyses[-1]                    exp_time = datetime.fromtimestamp(latest_analysis["exp"])                    if exp_time < current_time + timedelta(                        minutes=5                    ):\n  # Expira en 5 minutos                        expiring_tokens += 1            return {                "timestamp":\n current_time.isoformat(),                "status":\n "monitoring_active",                "metrics":\n {                    "total_requests_5min":\n total_requests,                    "failed_requests_5min":\n failed_requests,                    "success_rate_percent":\n round(success_rate, 2),                    "active_tokens":\n active_tokens,                    "expiring_tokens":\n expiring_tokens,                    "active_sessions":\n len(self.active_sessions),                    "error_patterns_count":\n len(self.error_patterns),                },                "recent_errors":\n dict(list(self.error_patterns.items())[:\n10]),                "performance":\n {                    "avg_response_time":\n self._calculate_avg_response_time(),                    "peak_error_rate":\n self._calculate_peak_error_rate(),                },            }    \ndef _calculate_avg_response_time(self) -> float:\n        """Calcular tiempo promedio de respuesta"""        if not self.performance_metrics:\n            return 0.0        total_time = sum(            metric.get("response_time", 0)            for metric in self.performance_metrics        )        return round(total_time / len(self.performance_metrics), 2)    \ndef _calculate_peak_error_rate(self) -> float:\n        """Calcular tasa máxima de errores"""        if not self.performance_metrics:\n            return 0.0        error_count = sum(            1            for metric in self.performance_metrics            if not metric.get("success", True)        )        return round((error_count / len(self.performance_metrics)) * 100, 2)# Instancia global del monitorauth_monitor = RealTimeAuthMonitor()# ============================================# ENDPOINTS DE MONITOREO# ============================================@router.get("/real-time-status")async \ndef get_real_time_status():\n    """    📊 Estado en tiempo real del sistema de autenticación    """    try:\n        status = auth_monitor.get_real_time_status()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "data":\n status,        }    except Exception as e:\n        logger.error(f"Error obteniendo estado en tiempo real:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/token-analysis/{user_id}")async \ndef analyze_user_tokens(    user_id:\n int,    db:\n Session = Depends(get_db),    current_user:\n User = Depends(get_current_user),):\n    """    🔍 Análisis detallado de tokens de un usuario específico    """    try:\n        # Verificar que el usuario existe        user = db.query(User).filter(User.id == user_id).first()        if not user:\n            return {                "timestamp":\n datetime.now().isoformat(),                "status":\n "error",                "error":\n "Usuario no encontrado",            }        # Buscar análisis de tokens para este usuario        user_token_analyses = []        for token_id, analyses in auth_monitor.token_analysis.items():\n            if analyses and str(analyses[0]["user_id"]) == str(user_id):\n                user_token_analyses.extend(analyses)        # Ordenar por tiempo más reciente        user_token_analyses.sort(key=lambda x:\n x["request_time"], reverse=True)        # Análisis estadístico        total_requests = len(user_token_analyses)        successful_requests = len(            [a for a in user_token_analyses if a.get("success", True)]        )        success_rate = (            (successful_requests / total_requests * 100)            if total_requests > 0            else 0        )        # Endpoints más usados        endpoint_usage = defaultdict(int)        for analysis in user_token_analyses:\n            endpoint_usage[analysis.get("endpoint", "unknown")] += 1        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "user":\n {                "id":\n user.id,                "email":\n user.email,                "is_active":\n user.is_active,                "is_admin":\n user.is_admin,            },            "analysis":\n {                "total_requests":\n total_requests,                "successful_requests":\n successful_requests,                "success_rate_percent":\n round(success_rate, 2),                "most_used_endpoints":\n dict(                    sorted(                        endpoint_usage.items(),                        key=lambda x:\n x[1],                        reverse=True,                    )[:\n10]                ),                "recent_requests":\n user_token_analyses[                    :\n20                ],  # Últimos 20 requests            },        }    except Exception as e:\n        logger.error(f"Error analizando tokens del usuario:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.post("/log-request")async \ndef log_request_data(request:\n Request, request_data:\n Dict[str, Any]):\n    """    📝 Endpoint para registrar datos de request (usado por middleware)    """    try:\n        # Agregar información adicional del request        enhanced_data = {            **request_data,            "client_ip":\n request.client.host,            "user_agent":\n request.headers.get("user-agent"),            "endpoint":\n str(request.url.path),            "method":\n request.method,        }        auth_monitor.log_request(enhanced_data)        return {"timestamp":\n datetime.now().isoformat(), "status":\n "logged"}    except Exception as e:\n        logger.error(f"Error registrando request:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/error-patterns")async \ndef get_error_patterns():\n    """    🚨 Patrones de error detectados    """    try:\n        with auth_monitor.lock:\n            patterns = dict(auth_monitor.error_patterns)        # Ordenar por frecuencia        sorted_patterns = sorted(            patterns.items(), key=lambda x:\n x[1], reverse=True        )        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "patterns":\n sorted_patterns,            "total_patterns":\n len(patterns),            "most_common_error":\n (                sorted_patterns[0] if sorted_patterns else None            ),        }    except Exception as e:\n        logger.error(f"Error obteniendo patrones de error:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/performance-metrics")async \ndef get_performance_metrics():\n    """    ⚡ Métricas de rendimiento del sistema    """    try:\n        status = auth_monitor.get_real_time_status()        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "metrics":\n status["metrics"],            "performance":\n status["performance"],            "recommendations":\n _generate_performance_recommendations(status),        }    except Exception as e:\n        logger.error(f"Error obteniendo métricas de rendimiento:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }\ndef _generate_performance_recommendations(status:\n Dict[str, Any]) -> List[str]:\n    """Generar recomendaciones basadas en métricas"""    recommendations = []    metrics = status.get("metrics", {})    success_rate = metrics.get("success_rate_percent", 100)    if success_rate < 95:\n        recommendations.append(            f"⚠️ Tasa de éxito baja"            + f"({success_rate}%) - Revisar c \            onfiguración de tokens"        )    expiring_tokens = metrics.get("expiring_tokens", 0)    if expiring_tokens > 0:\n        recommendations.append(            f"🔄 {expiring_tokens} tokens expirando pronto - Verificar  \            auto-refresh"        )    avg_response_time = status.get("performance", {}).get(        "avg_response_time", 0    )    if avg_response_time > 2.0:\n        recommendations.append(            f"🐌 Tiempo de respuesta alto ({avg_response_time}s) -     Optimizar queries"        )    if not recommendations:\n        recommendations.append("✅ Sistema funcionando correctamente")    return recommendations
