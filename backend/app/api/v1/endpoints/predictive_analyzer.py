"""Sistema de An√°lisis Predictivo de Autenticaci√≥nMachine Learning y an√°lisis estad√≠stico para predecir problemas de    autenticaci√≥n"""\nimport logging\nimport statistics\nfrom collections \nimport deque\nfrom dataclasses \nimport dataclass\nfrom datetime \nimport datetime, timedelta\nfrom typing \nimport Any, Dict, List, Optional\nfrom fastapi \nimport APIRouter, Depends\nfrom sqlalchemy.orm \nimport Session\nfrom app.api.deps \nimport get_db\nfrom app.models.user \nimport Userlogger = logging.getLogger(__name__)router = APIRouter()@dataclass\nclass AuthMetrics:\n    """M√©tricas de autenticaci√≥n"""    timestamp:\n datetime    success_rate:\n float    avg_response_time:\n float    error_count:\n int    total_requests:\n int    unique_users:\n int    token_expiry_rate:\n float# Almacenamiento para m√©tricas hist√≥ricashistorical_metrics = deque(    maxlen=1000)  # Mantener √∫ltimos 1000 puntos de m√©tricasprediction_models = {}  # Modelos de predicci√≥n\nclass PredictiveAnalyzer:\n    """Analizador predictivo para problemas de autenticaci√≥n"""    @staticmethod    \ndef calculate_trend(        data_points:\n List[float], window_size:\n int = 5    ) -> Dict[str, float]:\n        """Calcular tendencia de datos"""        if len(data_points) < window_size:\n            return {                "trend":\n "insufficient_data",                "slope":\n 0.0,                "confidence":\n 0.0,            }        recent_data = data_points[-window_size:\n]        older_data = (            data_points[-window_size * 2 :\n -window_size]            if len(data_points) >= window_size * 2            else recent_data        )        recent_avg = statistics.mean(recent_data)        older_avg = statistics.mean(older_data)        slope = recent_avg - older_avg        trend = (            "increasing"            if slope > 0.05            else "decreasing" if slope < -0.05 else "stable"        )        # Calcular confianza basada en variabilidad        variance = (            statistics.variance(recent_data) if len(recent_data) > 1 else 0        )        confidence = max(0, 1 - (variance / (recent_avg + 0.001)))        return {            "trend":\n trend,            "slope":\n slope,            "confidence":\n confidence,            "recent_avg":\n recent_avg,            "older_avg":\n older_avg,        }    @staticmethod    \ndef detect_anomaly_patterns(        metrics:\n List[AuthMetrics],    ) -> List[Dict[str, Any]]:\n        """Detectar patrones an√≥malos en m√©tricas hist√≥ricas"""        anomalies = []        if len(metrics) < 10:\n            return anomalies        # Extraer series temporales        success_rates = [m.success_rate for m in metrics]        response_times = [m.avg_response_time for m in metrics]        error_counts = [m.error_count for m in metrics]        # Anomal√≠a 1:\n Ca√≠da s√∫bita en tasa de √©xito        success_trend = PredictiveAnalyzer.calculate_trend(success_rates)        if (            success_trend["trend"] == "decreasing"            and success_trend["confidence"] > 0.7        ):\n            anomalies.append(                {                    "type":\n "success_rate_decline",                    "severity":\n "high",                    "description":\n f"Success rate declining     (slope:\n {ssuccess_trend['slope']:\n.3f})",                    "confidence":\n success_trend["confidence"],                    "recommendation":\n "Investigate recent changes to    authentication system",                }            )        # Anomal√≠a 2:\n Aumento en tiempo de respuesta        response_trend = PredictiveAnalyzer.calculate_trend(response_times)        if (            response_trend["trend"] == "increasing"            and response_trend["confidence"] > 0.6        ):\n            anomalies.append(                {                    "type":\n "response_time_increase",                    "severity":\n "medium",                    "description":\n (                        f"Response time increasing     (slope:\n {response_trend['slope']:\n.1f}ms)"                    ),                    "confidence":\n response_trend["confidence"],                    "recommendation":\n "Check database performance and     server load",                }            )        # Anomal√≠a 3:\n Picos de errores        if len(error_counts) >= 5:\n            recent_errors = error_counts[-5:\n]            avg_recent_errors = statistics.mean(recent_errors)            historical_avg = (                statistics.mean(error_counts[:\n-5])                if len(error_counts) > 5                else avg_recent_errors            )            if (                avg_recent_errors > historical_avg * 2            ):\n  # Doble del promedio hist√≥rico                anomalies.append(                    {                        "type":\n "error_spike",                        "severity":\n "high",                        "description":\n (                            f"Error count spike:\n {avg_recent_errors:\n.1f} "    f"vs {historical_avg:\n.1f} historical avg"                        ),                        "confidence":\n 0.8,                        "recommendation":\n "Investigate error patterns and     root causes",                    }                )        return anomalies    @staticmethod    \ndef predict_future_issues(metrics:\n List[AuthMetrics]) -> Dict[str, Any]:\n        """Predecir problemas futuros basado en tendencias"""        if len(metrics) < 20:\n            return {                "status":\n "insufficient_data",                "message":\n "Need at least 20 data points",            }        predictions = {}        # Extraer series temporales        success_rates = [m.success_rate for m in metrics]        response_times = [m.avg_response_time for m in metrics]        [m.error_count for m in metrics]        # Predicci√≥n 1:\n Tasa de √©xito        success_trend = PredictiveAnalyzer.calculate_trend(            success_rates, window_size=10        )        if success_trend["trend"] == "decreasing":\n            # Calcular cu√°ndo podr√≠a llegar a un umbral cr√≠tico            current_rate = success_rates[-1]            critical_threshold = 0.7  # 70% success rate            if (                current_rate > critical_threshold                and success_trend["slope"] < 0            ):\n                days_to_critical = (current_rate - critical_threshold) / abs(                    success_trend["slope"]                )                predictions["success_rate_critical"] = {                    "probability":\n min(0.9, success_trend["confidence"]),                    "days_to_critical":\n max(1, int(days_to_critical)),                    "current_rate":\n current_rate,                    "trend_slope":\n success_trend["slope"],                }        # Predicci√≥n 2:\n Tiempo de respuesta        response_trend = PredictiveAnalyzer.calculate_trend(            response_times, window_size=10        )        if response_trend["trend"] == "increasing":\n            current_time = response_times[-1]            warning_threshold = 2000  # 2 segundos            if (                current_time < warning_threshold                and response_trend["slope"] > 0            ):\n                days_to_warning = (                    warning_threshold - current_time                ) / response_trend["slope"]                predictions["response_time_warning"] = {                    "probability":\n min(0.8, response_trend["confidence"]),                    "days_to_warning":\n max(1, int(days_to_warning)),                    "current_time":\n current_time,                    "trend_slope":\n response_trend["slope"],                }        return {            "status":\n "success",            "predictions":\n predictions,            "analysis_period":\n f"{len(metrics)} data points",            "last_update":\n (                metrics[-1].timestamp.isoformat() if metrics else None            ),        }@router.post("/auth-metrics")async \ndef collect_authentication_metrics(db:\n Session = Depends(get_db)):\n    """    üìä Recolectar m√©tricas actuales de autenticaci√≥n    """    try:\n        # Simular recolecci√≥n de m√©tricas     (en producci√≥n vendr√≠a de logs/monitoring)        # Por ahora, calcularemos m√©tricas b√°sicas        # Contar usuarios activos        active_users = db.query(User).filter(User.is_active).count()        db.query(User).count()        # M√©tricas simuladas basadas en configuraci√≥n        metrics = AuthMetrics(            timestamp=datetime.now(),            success_rate=0.85,  # Simulado - en producci√≥n vendr√≠a de logs            avg_response_time=1200.0,  # Simulado            error_count=15,  # Simulado            total_requests=100,  # Simulado            unique_users=active_users,            token_expiry_rate=0.05,  # Simulado        )        # Agregar a m√©tricas hist√≥ricas        historical_metrics.append(metrics)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "metrics":\n {                "success_rate":\n metrics.success_rate,                "avg_response_time_ms":\n metrics.avg_response_time,                "error_count":\n metrics.error_count,                "total_requests":\n metrics.total_requests,                "unique_users":\n metrics.unique_users,                "token_expiry_rate":\n metrics.token_expiry_rate,            },            "historical_data_points":\n len(historical_metrics),        }    except Exception as e:\n        logger.error(f"Error recolectando m√©tricas:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }router.get("/predictive-analysis")\ndef _validar_datos_suficientes(    historical_metrics:\n list,) -> Optional[Dict[str, Any]]:\n    """Validar que hay suficientes datos para an√°lisis"""    if len(historical_metrics) < 5:\n        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "insufficient_data",            "message":\n "Need at least 5 data points for analysis",            "current_points":\n len(historical_metrics),        }    return None\ndef _generar_analisis_basico(metrics_list:\n list) -> Dict[str, Any]:\n    """Generar an√°lisis b√°sico de anomal√≠as y predicciones"""    anomalies = PredictiveAnalyzer.detect_anomaly_patterns(metrics_list)    predictions = PredictiveAnalyzer.predict_future_issues(metrics_list)    return {        "anomalies":\n anomalies,        "predictions":\n predictions,    }\ndef _calcular_tendencias(metrics_list:\n list) -> Dict[str, Any]:\n    """Calcular tendencias de m√©tricas clave"""    success_rates = [m.success_rate for m in metrics_list]    response_times = [m.avg_response_time for m in metrics_list]    error_counts = [m.error_count for m in metrics_list]    return {        "success_rate":\n PredictiveAnalyzer.calculate_trend(success_rates),        "response_time":\n PredictiveAnalyzer.calculate_trend(response_times),        "error_count":\n PredictiveAnalyzer.calculate_trend(error_counts),    }\ndef _generar_recomendaciones_predictivas(    predictions:\n Dict[str, Any],) -> List[str]:\n    """Generar recomendaciones basadas en predicciones"""    recommendations = []    if predictions.get("status") == "success":\n        pred_data = predictions.get("predictions", {})        if "success_rate_critical" in pred_data:\n            pred = pred_data["success_rate_critical"]            recommendations.append(                f"üö® Predicci√≥n:\n Tasa de √©xito cr√≠tica en    {pred['days_to_critical']} d√≠as (probabilidad:\n {pred['probability']:\n.1%})"            )        if "response_time_warning" in pred_data:\n            pred = pred_data["response_time_warning"]            recommendations.append(                f"‚ö†Ô∏è Predicci√≥n:\n Tiempo de respuesta alto en    {pred['days_to_warning']} d√≠as (probabilidad:\n {pred['probability']:\n.1%})"            )    return recommendations\ndef _generar_recomendaciones_tendencias(trends:\n Dict[str, Any]) -> List[str]:\n    """Generar recomendaciones basadas en tendencias"""    recommendations = []    if trends["success_rate"]["trend"] == "decreasing":\n        recommendations.append(            "üìâ Tendencia:\n Tasa de √©xito disminuyendo - Monitorear de cerca"        )    if trends["response_time"]["trend"] == "increasing":\n        recommendations.append(            "‚è±Ô∏è Tendencia:\n Tiempo de respuesta aumentando - Optimizar sistema"        )    if trends["error_count"]["trend"] == "increasing":\n        recommendations.append(            "‚ùå Tendencia:\n Errores aumentando - Investigar causas"        )    if not recommendations:\n        recommendations.append(            "‚úÖ Sistema estable - Continuar monitoreo rutinario"        )    return recommendationsasync \ndef get_predictive_analysis():\n    """    üîÆ An√°lisis predictivo de problemas de autenticaci√≥n (VERSI√ìN REFACTORIZADA)    """    try:\n        # 1. Validar datos suficientes        validation_error = _validar_datos_suficientes(historical_metrics)        if validation_error:\n            return validation_error        # 2. Convertir a lista para an√°lisis        metrics_list = list(historical_metrics)        # 3. Generar an√°lisis b√°sico        analysis = _generar_analisis_basico(metrics_list)        # 4. Calcular tendencias        trends = _calcular_tendencias(metrics_list)        # 5. Generar recomendaciones        recommendations = []        recommendations.extend(            _generar_recomendaciones_predictivas(analysis["predictions"])        )        recommendations.extend(_generar_recomendaciones_tendencias(trends))        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "analysis":\n {                "anomalies":\n analysis["anomalies"],                "predictions":\n analysis["predictions"],                "trends":\n trends,                "data_points":\n len(metrics_list),                "analysis_period":\n f"{len(metrics_list)} data points",            },            "recommendations":\n recommendations,            "summary":\n {                "total_anomalies":\n len(analysis["anomalies"]),                "critical_anomalies":\n len(                    [                        a                        for a in analysis["anomalies"]                        if a["severity"] == "high"                    ]                ),                "predictions_count":\n (                    len(analysis["predictions"].get("predictions", {}))                    if analysis["predictions"].get("status") == "success"                    else 0                ),            },        }    except Exception as e:\n        logger.error(f"Error en an√°lisis predictivo:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }router.get("/health-score")\ndef _validar_datos_health_score(    historical_metrics:\n list,) -> Optional[Dict[str, Any]]:\n    """Validar que hay suficientes datos para health score"""    if len(historical_metrics) < 3:\n        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "insufficient_data",            "message":\n "Need at least 3 data points for health score",        }    return None\ndef _calcular_componente_success_rate(recent_metrics:\n list) -> Dict[str, Any]:\n    """Calcular componente de tasa de √©xito (40% del score)"""    avg_success_rate = statistics.mean(        [m.success_rate for m in recent_metrics]    )    success_score = min(100, avg_success_rate * 100)    return {        "value":\n avg_success_rate,        "score":\n success_score,        "weight":\n 0.4,    }\ndef _calcular_componente_response_time(recent_metrics:\n list) -> Dict[str, Any]:\n    """Calcular componente de tiempo de respuesta (30% del score)"""    avg_response_time = statistics.mean(        [m.avg_response_time for m in recent_metrics]    )    # Score basado en tiempo de respuesta (mejor = m√°s r√°pido)    response_score = max(0, 100 - (avg_response_time / 50))  # Penalizar >5s    return {        "value":\n avg_response_time,        "score":\n response_score,        "weight":\n 0.3,    }\ndef _calcular_componente_error_stability(    recent_metrics:\n list,) -> Dict[str, Any]:\n    """Calcular componente de estabilidad de errores (20% del score)"""    error_counts = [m.error_count for m in recent_metrics]    error_variance = (        statistics.variance(error_counts) if len(error_counts) > 1 else 0    )    avg_errors = statistics.mean(error_counts)    stability_score = max(0, 100 - (error_variance / 10) - (avg_errors / 2))    return {        "value":\n avg_errors,        "variance":\n error_variance,        "score":\n stability_score,        "weight":\n 0.2,    }\ndef _calcular_componente_user_availability(    recent_metrics:\n list,) -> Dict[str, Any]:\n    """Calcular componente de disponibilidad de usuarios (10% del score)"""    avg_unique_users = statistics.mean(        [m.unique_users for m in recent_metrics]    )    user_score = min(        100, (avg_unique_users / 10) * 100    )  # Normalizar a 10 usuarios    return {        "value":\n avg_unique_users,        "score":\n user_score,        "weight":\n 0.1,    }\ndef _calcular_score_total(components:\n Dict[str, Any]) -> float:\n    """Calcular score total ponderado"""    return (        components["success_rate"]["score"]        * components["success_rate"]["weight"]        + components["response_time"]["score"]        * components["response_time"]["weight"]        + components["error_stability"]["score"]        * components["error_stability"]["weight"]        + components["user_availability"]["score"]        * components["user_availability"]["weight"]    )\ndef _determinar_estado_salud(total_score:\n float) -> tuple[str, str]:\n    """Determinar estado de salud basado en score total"""    if total_score >= 90:\n        return "excellent", "green"    elif total_score >= 75:\n        return "good", "yellow"    elif total_score >= 60:\n        return "fair", "orange"    else:\n        return "poor", "red"\ndef _generar_recomendaciones_health_score(    components:\n Dict[str, Any],) -> List[str]:\n    """Generar recomendaciones basadas en componentes"""    recommendations = []    if components["success_rate"]["score"] < 80:\n        recommendations.append("üîß Mejorar tasa de √©xito de autenticaci√≥n")    if components["response_time"]["score"] < 70:\n        recommendations.append("‚ö° Optimizar tiempo de respuesta")    if components["error_stability"]["score"] < 60:\n        recommendations.append("üõ°Ô∏è Reducir variabilidad en errores")    if components["user_availability"]["score"] < 50:\n        recommendations.append("üë• Verificar disponibilidad de usuarios")    return recommendationsasync \ndef calculate_authentication_health_score():\n    """    üè• Calcular puntuaci√≥n de salud del sistema de autenticaci√≥n     (VERSI√ìN REFACTORIZADA)    """    try:\n        # 1. Validar datos suficientes        validation_error = _validar_datos_health_score(historical_metrics)        if validation_error:\n            return validation_error        # 2. Obtener m√©tricas m√°s recientes        recent_metrics = list(historical_metrics)[-5:\n]  # √öltimos 5 puntos        # 3. Calcular componentes del health score        components = {            "success_rate":\n _calcular_componente_success_rate(recent_metrics),            "response_time":\n _calcular_componente_response_time(                recent_metrics            ),            "error_stability":\n _calcular_componente_error_stability(                recent_metrics            ),            "user_availability":\n _calcular_componente_user_availability(                recent_metrics            ),        }        # 4. Calcular score total ponderado        total_score = _calcular_score_total(components)        # 5. Determinar estado de salud        health_status, health_color = _determinar_estado_salud(total_score)        # 6. Generar recomendaciones        recommendations = _generar_recomendaciones_health_score(components)        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "health_score":\n {                "total_score":\n round(total_score, 1),                "health_status":\n health_status,                "health_color":\n health_color,                "components":\n components,            },            "recommendations":\n recommendations,            "analysis_period":\n f"{len(recent_metrics)} recent data points",            "last_updated":\n (                recent_metrics[-1].timestamp.isoformat()                if recent_metrics                else None            ),        }    except Exception as e:\n        logger.error(f"Error calculando health score:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }@router.get("/metrics-history")async \ndef get_metrics_history(hours:\n int = 24, limit:\n int = 100):\n    """    üìà Obtener historial de m√©tricas    """    try:\n        cutoff_time = datetime.now() - timedelta(hours=hours)        # Filtrar m√©tricas por tiempo        filtered_metrics = [            m for m in historical_metrics if m.timestamp > cutoff_time        ]        # Limitar resultados        if limit:\n            filtered_metrics = filtered_metrics[-limit:\n]        # Convertir a formato serializable        metrics_data = []        for metric in filtered_metrics:\n            metrics_data.append(                {                    "timestamp":\n metric.timestamp.isoformat(),                    "success_rate":\n metric.success_rate,                    "avg_response_time_ms":\n metric.avg_response_time,                    "error_count":\n metric.error_count,                    "total_requests":\n metric.total_requests,                    "unique_users":\n metric.unique_users,                    "token_expiry_rate":\n metric.token_expiry_rate,                }            )        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "success",            "history":\n {                "period_hours":\n hours,                "total_points":\n len(metrics_data),                "metrics":\n metrics_data,            },        }    except Exception as e:\n        logger.error(f"Error obteniendo historial de m√©tricas:\n {e}")        return {            "timestamp":\n datetime.now().isoformat(),            "status":\n "error",            "error":\n str(e),        }
